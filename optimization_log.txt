=== BASELINE MEASUREMENT ===
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      20	  27184742 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	0.764s

=== PHASE 1.1: RoPE PRE-COMPUTATION ===
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      20	  24645440 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	0.725s

=== PHASE 1.2: FAST GELU APPROXIMATION ===
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      20	  24010806 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	0.700s

=== PHASE 1.3: MEMORY POOLING ===
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      20	  23505118 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	0.722s
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	0.003s
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	0.003s
--- FAIL: TestEmbeddingGemmaFullPipeline (0.13s)
    embeddinggemma_test.go:31: Loading EmbeddingGemma model...
    embeddinggemma_test.go:40: Model configuration:
    embeddinggemma_test.go:41:   Vocab size: 262144
    embeddinggemma_test.go:42:   Embed dim: 768
    embeddinggemma_test.go:43:   Layers: 24
    embeddinggemma_test.go:44:   Heads: 3
    embeddinggemma_test.go:45:   Max seq len: 2048
    embeddinggemma_test.go:56: 
        Tokenizing: "Hello world"
    embeddinggemma_test.go:61:   Token IDs: [2 9259 1902 1]
    embeddinggemma_test.go:62:   Token count: 4
    embeddinggemma_test.go:65: 
        Generating embedding...
    embeddinggemma_test.go:76: 
        Comparing with llama.cpp reference:
    embeddinggemma_test.go:77:   Our first 20 values:
    embeddinggemma_test.go:79:     [ 0] 0.045774
    embeddinggemma_test.go:79:     [ 1] 0.009010
    embeddinggemma_test.go:79:     [ 2] -0.022650
    embeddinggemma_test.go:79:     [ 3] 0.043824
    embeddinggemma_test.go:79:     [ 4] -0.013583
    embeddinggemma_test.go:79:     [ 5] -0.071876
    embeddinggemma_test.go:79:     [ 6] -0.018230
    embeddinggemma_test.go:79:     [ 7] 0.005763
    embeddinggemma_test.go:79:     [ 8] 0.031927
    embeddinggemma_test.go:79:     [ 9] 0.007501
    embeddinggemma_test.go:79:     [10] -0.018759
    embeddinggemma_test.go:79:     [11] -0.051491
    embeddinggemma_test.go:79:     [12] 0.004494
    embeddinggemma_test.go:79:     [13] 0.033835
    embeddinggemma_test.go:79:     [14] -0.025855
    embeddinggemma_test.go:79:     [15] 0.014448
    embeddinggemma_test.go:79:     [16] 0.012796
    embeddinggemma_test.go:79:     [17] 0.005228
    embeddinggemma_test.go:79:     [18] 0.009706
    embeddinggemma_test.go:79:     [19] -0.060937
    embeddinggemma_test.go:82: 
          llama.cpp reference:
    embeddinggemma_test.go:84:     [ 0] 0.045353
    embeddinggemma_test.go:84:     [ 1] 0.019009
    embeddinggemma_test.go:84:     [ 2] -0.023062
    embeddinggemma_test.go:84:     [ 3] 0.048222
    embeddinggemma_test.go:84:     [ 4] -0.015216
    embeddinggemma_test.go:84:     [ 5] -0.064155
    embeddinggemma_test.go:84:     [ 6] -0.010043
    embeddinggemma_test.go:84:     [ 7] 0.017571
    embeddinggemma_test.go:84:     [ 8] 0.030328
    embeddinggemma_test.go:84:     [ 9] 0.002995
    embeddinggemma_test.go:84:     [10] -0.024283
    embeddinggemma_test.go:84:     [11] -0.060874
    embeddinggemma_test.go:84:     [12] 0.007241
    embeddinggemma_test.go:84:     [13] 0.030302
    embeddinggemma_test.go:84:     [14] -0.026810
    embeddinggemma_test.go:84:     [15] 0.016176
    embeddinggemma_test.go:84:     [16] 0.014976
    embeddinggemma_test.go:84:     [17] 0.004858
    embeddinggemma_test.go:84:     [18] 0.014418
    embeddinggemma_test.go:84:     [19] -0.058049
    embeddinggemma_test.go:98: 
          Max difference: 0.011808 at index 7
    embeddinggemma_test.go:99:     Our value:   0.005763
    embeddinggemma_test.go:100:     Reference:   0.017571
    embeddinggemma_test.go:106: Max difference 0.011808 exceeds tolerance 0.010000
FAIL
exit status 1
FAIL	github.com/lth/pure-go-llamas/internal/runtime	0.820s
FAIL
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      48	  22265090 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	1.759s

=== PHASE 2.1: FUSED BLOCK PROCESSING ===
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      48	  22265090 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	1.759s

=== OPTIMIZATION SUMMARY ===
Baseline:    27.18ms
Phase 1.1:   24.65ms  (-2.53ms, 1.10x)  RoPE pre-computation
Phase 1.2:   24.01ms  (-0.64ms, 1.03x)  Fast GELU approximation
Phase 1.3:   23.51ms  (-0.50ms, 1.02x)  Memory pooling
Phase 2.1:   22.27ms  (-1.24ms, 1.06x)  Fused block processing

Total improvement: 27.18ms â†’ 22.27ms
Cumulative speedup: 1.22x (18% faster)
Total time saved: 4.91ms per inference
