=========================================
BASELINE PERFORMANCE METRICS
=========================================
Date: Fri Oct 24 11:13:57 PM MDT 2025
System: Linux rainbow 6.17.2-arch1-1 #1 SMP PREEMPT_DYNAMIC Sun, 12 Oct 2025 12:45:18 +0000 x86_64 GNU/Linux

=========================================
1. BenchmarkForwardINT8
=========================================
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      10	  42440100 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	0.743s

=========================================
2. TestMemoryUsage
=========================================
=== RUN   TestMemoryUsage
    memory_test.go:20: Before LoadModel:
    memory_test.go:21:   Alloc: 0.33 MB
    memory_test.go:22:   HeapAlloc: 0.33 MB
    memory_test.go:34: 
        After LoadModel:
    memory_test.go:35:   Alloc: 412.84 MB
    memory_test.go:36:   HeapAlloc: 412.84 MB
    memory_test.go:39: 
        Memory increase from model: 412.50 MB
    memory_test.go:40: GGUF file size: ~314 MB
    memory_test.go:41: Expected: GGUF (~314 MB) + tokenizer (~90 MB) + norms (~10 MB) = ~414 MB
    memory_test.go:47: ✅ Zero-copy SUCCESS! Memory: 412.50 MB (GGUF + tokenizer + norms)
    memory_test.go:60: 
        After Forward():
    memory_test.go:61:   Alloc: 413.19 MB
    memory_test.go:62:   HeapAlloc: 413.19 MB
    memory_test.go:65: 
        Total memory footprint: 412.86 MB
    memory_test.go:68: 
        Zero-copy architecture:
    memory_test.go:69:   GGUF file in memory: ~314 MB (loaded once)
    memory_test.go:70:   Token embeddings: 0 MB (slice view into GGUF)
    memory_test.go:71:   Layer weights: 0 MB (slice views into GGUF)
    memory_test.go:72:   Tokenizer vocab: ~90 MB
    memory_test.go:73:   FP32 norm weights: ~5-10 MB
    memory_test.go:74:   Total expected: ~414 MB
--- PASS: TestMemoryUsage (0.23s)
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	(cached)

=========================================
3. TestINT8Accuracy
=========================================
=== RUN   TestINT8Accuracy
    int8_test.go:23: Testing text: "Hello world"
    int8_test.go:30: Token IDs: [2 9259 1902 1]
    int8_test.go:33: 
        === FP32 Inference ===
    int8_test.go:38: FP32 first 10: 0.046705 0.007719 -0.021178 0.042897 -0.018340 -0.059965 -0.015262 0.010984 0.032365 0.005280
    int8_test.go:43: 
        === INT8 Inference ===
    int8_test.go:48: INT8 first 10: 0.046705 0.007719 -0.021178 0.042897 -0.018340 -0.059965 -0.015262 0.010984 0.032365 0.005280
    int8_test.go:59: 
        Cosine similarity (INT8 vs FP32): 1.000000
    int8_test.go:80: 
        Numerical comparison:
    int8_test.go:81:   Max difference:  0.000000 at index 0
    int8_test.go:82:     FP32 value:    0.046705
    int8_test.go:83:     INT8 value:    0.046705
    int8_test.go:84:   Avg difference:  0.000000
    int8_test.go:85:   RMS difference:  0.000000
    int8_test.go:93: 
        ✅ INT8 accuracy acceptable: 1.000000 >= 0.95
--- PASS: TestINT8Accuracy (0.26s)
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	(cached)

=========================================
SUMMARY
=========================================

KEY METRICS:
-----------
BenchmarkForwardINT8:    42,440,100 ns/op (42.44 ms per inference)
TestMemoryUsage:         412.86 MB total memory footprint
TestINT8Accuracy:        Cosine similarity = 1.000000 (perfect accuracy)

DETAILED BREAKDOWN:
------------------
Memory Usage:
  - GGUF file in memory:       ~314 MB
  - Tokenizer vocab:           ~90 MB
  - FP32 norm weights:         ~5-10 MB
  - Total:                     412.86 MB
  - Status:                    ✅ Zero-copy SUCCESS!

INT8 Accuracy:
  - Cosine similarity:         1.000000 (target: ≥ 0.95)
  - Max difference:            0.000000
  - Avg difference:            0.000000
  - RMS difference:            0.000000
  - Status:                    ✅ PASS (perfect match)

Performance:
  - Inference time:            42.44 ms per forward pass
  - Test system:               AMD Ryzen 9 7900 12-Core (24 threads)
  - Platform:                  Linux x86_64

NOTE: INT8 currently shows perfect accuracy (1.000000) which suggests
the INT8 implementation may not be using actual quantization yet, or
the quantization error is negligible for this test case.

