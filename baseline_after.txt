=== BENCHMARK: BenchmarkForwardINT8 ===
goos: linux
goarch: amd64
pkg: github.com/lth/pure-go-llamas/internal/runtime
cpu: AMD Ryzen 9 7900 12-Core Processor             
BenchmarkForwardINT8-24    	      10	  66501242 ns/op
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	1.050s

=== TEST: TestMemoryUsage ===
=== RUN   TestMemoryUsage
    memory_test.go:20: Before LoadModel:
    memory_test.go:21:   Alloc: 0.37 MB
    memory_test.go:22:   HeapAlloc: 0.37 MB
    memory_test.go:34: 
        After LoadModel:
    memory_test.go:35:   Alloc: 412.91 MB
    memory_test.go:36:   HeapAlloc: 412.91 MB
    memory_test.go:39: 
        Memory increase from model: 412.54 MB
    memory_test.go:40: GGUF file size: ~314 MB
    memory_test.go:41: Expected: GGUF (~314 MB) + tokenizer (~90 MB) + norms (~10 MB) + scales (~10 MB) = ~424 MB
    memory_test.go:48: ✅ Zero-copy SUCCESS! Memory: 412.54 MB (GGUF + tokenizer + norms + scales)
    memory_test.go:61: 
        After Forward():
    memory_test.go:62:   Alloc: 425.58 MB
    memory_test.go:63:   HeapAlloc: 425.58 MB
    memory_test.go:66: 
        Total memory footprint: 425.22 MB
    memory_test.go:69: 
        Zero-copy architecture:
    memory_test.go:70:   GGUF file in memory: ~314 MB (loaded once)
    memory_test.go:71:   Token embeddings: 0 MB (slice view into GGUF)
    memory_test.go:72:   Layer weights: 0 MB (slice views into GGUF)
    memory_test.go:73:   Tokenizer vocab: ~90 MB
    memory_test.go:74:   FP32 norm weights: ~5-10 MB
    memory_test.go:75:   Pre-converted scales: ~10 MB (18 layers × 7 weights)
    memory_test.go:76:   Total expected: ~424 MB
--- PASS: TestMemoryUsage (0.29s)
PASS
ok  	github.com/lth/pure-go-llamas/internal/runtime	(cached)
